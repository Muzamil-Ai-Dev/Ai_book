---
id: "0001"
title: "Create Grounded RAG Chatbot Specification"
stage: "spec"
date: "2025-12-19"
surface: "agent"
model: "gemini-2.0-flash-thinking-exp"
feature: "008-rag-chatbot"
branch: "008-rag-chatbot"
user: "Muzamil"
command: "/sp.specify"
labels: ["rag", "chatbot", "specification", "grounding"]
links:
  spec: "specs/008-rag-chatbot/spec.md"
  ticket: "null"
  adr: "null"
  pr: "null"
files:
  - specs/008-rag-chatbot/spec.md
  - specs/008-rag-chatbot/checklists/requirements.md
tests:
  - "Specification Quality Checklist"
---

## Prompt

Create a specification for implementing a Retrieval-Augmented Generation (RAG) chatbot for the AI-Native Textbook for Physical AI & Humanoid Robotics. This chatbot is a core AI-Native feature and must demonstrate grounded, non-hallucinating intelligence. â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ PURPOSE â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Enable users to ask questions and receive answers strictly grounded in the textbookâ€™s Markdown content. The chatbot must: â€¢ Answer ONLY from book content â€¢ Refuse to answer when information is missing â€¢ Expose retrieved sources for transparency â€¢ Demonstrate AI-Native learning behavior â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ARCHITECTURE REQUIREMENTS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â€¢ Backend: FastAPI â€¢ Orchestration: OpenAI ChatKit SDK â€¢ LLM for response generation: Gemini (via Gemini API key) â€¢ Retrieval: Embeddings + vector database â€¢ Grounding: Context-7 MCP server (mandatory) â€¢ Content source: Docusaurus Markdown â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ CONTENT SOURCE â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â€¢ Canonical source: content/modules/ â€¢ Each Markdown chapter is a retrievable unit â€¢ Content must be chunked with metadata: - module - chapter - heading - file path â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ CORE COMPONENTS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 1. INGESTION PIPELINE â€¢ Read Markdown files from content/modules/ â€¢ Chunk content deterministically â€¢ Generate embeddings â€¢ Store embeddings in vector DB â€¢ Preserve source metadata Endpoint: POST /ingest â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 2. RETRIEVAL + GROUNDING â€¢ Retrieve top-K relevant chunks â€¢ Pass retrieved context through Context-7 MCP â€¢ Apply relevance filtering â€¢ If confidence is low â†’ refuse Context-7 must ensure: â€¢ No external knowledge â€¢ No speculative answers â€¢ Hard grounding to retrieved text â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 3. RESPONSE GENERATION â€¢ OpenAI ChatKit is used to orchestrate the flow: - user question - retrieved context - refusal rules â€¢ Gemini LLM is used ONLY for final response generation â€¢ Gemini must not receive any information outside retrieved context â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 4. QUERY ENDPOINT Endpoint: POST /query Behavior: â€¢ Accepts user question â€¢ Retrieves relevant content â€¢ Applies Context-7 grounding â€¢ Uses ChatKit + Gemini to generate response â€¢ Returns: - answer - sources used - refusal reason (if applicable) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ NON-FUNCTIONAL REQUIREMENTS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â€¢ Deterministic chunking â€¢ No hardcoded secrets â€¢ Environment variables only â€¢ Clear logging for: - retrieved chunks - grounding decisions â€¢ Simple JSON responses (no UI logic) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ VERIFICATION CRITERIA â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â€¢ Questions answerable from the book â†’ correct grounded response â€¢ Questions not in the book â†’ refusal â€¢ Logs show retrieved source files â€¢ Gemini responses never exceed provided context â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ OUTCOME â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ A production-ready, AI-Native RAG chatbot that proves the textbook is interactive, grounded, and non-hallucinating. This system is evaluated as a core hackathon deliverable.

## Response snapshot

Created a comprehensive feature specification for the Grounded RAG Chatbot. The specification includes four user scenarios (covering core answering, refusal, transparency, and conversational learning), a dedicated section for Architectural Constraints (FastAPI, Gemini, Context-7), and detailed functional requirements. It explicitly defines the mandatory metadata for chunking (module, chapter, heading, file path) and introduces a cross-verification grounding check. A quality checklist was used to validate the spec before and after these refinements.

## Outcome

- âœ… Impact: High - Defines the core AI feature and its architectural boundaries for the hackathon.
- ğŸ§ª Tests: Validated against Specification Quality Checklist.
- ğŸ“ Files: Created spec.md and requirements checklist.
- ğŸ” Next prompts: /sp.plan
- ğŸ§  Reflection: Successfully balanced the need for technology-agnostic requirements with the user's explicit architectural constraints. The addition of conversational memory better captures the "AI-Native learning" goal.

## Evaluation notes (flywheel)

- Failure modes observed: Initial spec contained implementation details; corrected in iteration.
- Graders run and results (PASS/FAIL): PASS
- Prompt variant (if applicable): null
- Next experiment (smallest change to try): null