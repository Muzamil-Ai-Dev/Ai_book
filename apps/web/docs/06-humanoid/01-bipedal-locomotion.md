---
id: bipedal-locomotion
title: "Deep Dive: The Math of Walking"
sidebar_label: ZMP & LIPM
description: "Understanding the Linear Inverted Pendulum Mode (LIPM) and Zero Moment Point (ZMP)."
---

# Deep Dive: The Math of Walking

## Learning Objectives

By the end of this chapter, you will be able to:

1.  **Derive the LIPM**, simplifying a complex robot into a single point mass on a massless stick.
2.  **Calculate the ZMP**, determining if a robot is about to tip over based on its acceleration.
3.  **Simulate a Step**, writing a Python script to predict the Center of Mass trajectory.
4.  **Contrast ZMP vs. MPC**, understanding why modern robots (like Atlas) use Model Predictive Control to survive pushes.

## Concept Explanations

### 1. The Linear Inverted Pendulum Mode (LIPM)

A humanoid robot has 20+ links. The math is a nightmare.
To solve walking, we simplify. We pretend the entire robot is just one **Point Mass** located at its Center of Mass (CoM), connected to the ground by a telescoping leg.

We constrain the CoM to stay at a constant height $H$.
This turns the non-linear pendulum equation into a **Linear** equation.

**The Equation of Motion**:
$$ \ddot{x} = \frac{g}{H} (x - p) $$

*   $\ddot{x}$: Acceleration of the CoM.
*   $g$: Gravity (9.81).
*   $H$: Constant height of the CoM.
*   $x$: Position of the CoM.
*   $p$: Position of the Foot (Center of Pressure).

**Interpretation**:
The acceleration ($\ddot{x}$) is proportional to how far the body ($x$) is leaning away from the foot ($p$).
*   If $x = p$ (Body over foot), acceleration is 0. You are balanced.
*   If $x > p$ (Body ahead of foot), acceleration is positive. You fall forward.

### 2. The Zero Moment Point (ZMP)

The **ZMP** is a point on the ground where the total torque generated by gravity and inertia is zero.
**The Rule**: To stay stable, the ZMP must stay *inside* the Support Polygon (the footprint).

*   If ZMP is inside the foot: The foot stays flat. Stable.
*   If ZMP reaches the edge of the foot: The foot starts to roll. You begin to tip.

**Kajita's Insight (2001)**:
Instead of trying to keep the ZMP fixed, we *plan* a desired ZMP trajectory (e.g., "Center of left foot" -> "Center of right foot"). Then we calculate the CoM trajectory ($x$) that generates that ZMP.

### 3. Model Predictive Control (MPC)

ZMP assumes everything goes to plan. But what if someone shoves the robot?
**MPC** is the solution.
*   **Lookahead**: "If I take Step A, then Step B, then Step C..."
*   **Optimization**: "...minimize the difference between my actual ZMP and desired ZMP."
*   **Receding Horizon**: Calculate for the next 1 second. Execute 0.01 seconds. Measure reality. Re-calculate.

This allows the robot to react. "Oh, I was pushed left? The optimization says I should step wider to the left to catch myself."

## Conceptual Visualization

### The "Cart-Table" Model

Imagine a cart with an inverted pendulum (a stick with a weight) on top of it.
*   The **Cart** is the Feet.
*   The **Pendulum** is the Body.

If the pendulum starts falling forward, you must accelerate the cart **forward** to catch it.
If you accelerate too much, the pendulum falls backward.
You are constantly juggling the pendulum by moving the cart.

## Hands-on Exercises

### Simulating LIPM in Python

Let's simulate the equation $\ddot{x} = \omega^2 (x - p)$.

```python
import numpy as np
import matplotlib.pyplot as plt

# Constants
g = 9.81
H = 1.0 # Com Height (meters)
omega_sq = g / H
dt = 0.01 # 10ms
steps = 100

# State
x = 0.0      # Position
dx = 1.0     # Velocity (Moving forward at 1m/s)
p = 0.0      # Foot position (Support foot at 0)

# Lists for plotting
t_list = []
x_list = []

for i in range(steps):
    # 1. Physics: LIPM Equation
    # Acceleration depends on distance from foot
    ddx = omega_sq * (x - p)
    
    # 2. Integration (Euler)
    dx += ddx * dt
    x += dx * dt
    
    t_list.append(i * dt)
    x_list.append(x)
    
    # Switch foot? (Simple walking logic)
    # If we drift too far (0.3m), move foot forward
    if x > p + 0.3:
        p += 0.6 # Take a 60cm step

plt.plot(t_list, x_list)
plt.xlabel("Time (s)")
plt.ylabel("CoM Position (m)")
plt.title("LIPM Trajectory: The Divergent Component")
# plt.show()
```

**Outcome**:
You will see an exponential curve. The robot drifts away from the foot faster and faster until the foot switches ($p$ changes). Then the error resets, and it drifts again.
This zig-zag is "Walking."

## Capstone Prep

### The RL Reward Function

Since we are using Reinforcement Learning (RL) instead of analytical ZMP, we need to translate these physics into rewards.

**LIPM-inspired Rewards**:
1.  **Verticality**: `reward += (z_head - z_target)**2`. (Keep $H$ constant, like LIPM).
2.  **Forward Velocity**: `reward += v_x`. (Like the $dx$ in our code).
3.  **Energy Penalty**: `reward -= torque**2`. (Don't flail).

If we tune these right, the Neural Network effectively "learns" the LIPM equation implicitly.